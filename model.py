import csv
import cv2
import time
import json

import tensorflow as tf

from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

import numpy as np

from keras.models import Sequential
from keras.layers import Input
from keras.layers.core import Dense, Dropout, Activation, Flatten, Lambda
from keras.optimizers import SGD, Adam, RMSprop
from keras.utils import np_utils
from keras.models import model_from_json
from keras.layers.convolutional import Convolution2D
from keras.layers.convolutional import Conv2D
from keras.layers.advanced_activations import ELU
from keras.wrappers.scikit_learn import KerasRegressor

####################################################################
# Reading the training data generated by the simulator
####################################################################
ifile  = open('/Users/sharanyadoddapaneni/nanodegree/selfdriving/behavioral-cloning/driving_log.csv', "rt")
reader = csv.reader(ifile)

####################################################################
# The implementation only considers the center images as the input to the neural network. 
# The output is the steering angle.
####################################################################
center_image = []
steering_angle = []

i = 0
for row in reader:
    if i > 0 :
        center_image.append(row[0])
        steering_angle.append(row[3])
    i = i+1

ifile.close()

######################################################
# input features and output labels
######################################################
print("No. of center images = ",len(center_image))
print("No. of steering angles = ",len(steering_angle))

####################################################################
# The feature dimenstions for the images generated by the simulator 
# for the center camera are 320x160Since the images with RGB
# colors, so the input shape = (num_images,160,320,3)
####################################################################
num_images = len(center_image)
image_rows = 160
image_columns = 320
image_channels = 3


grey = np.zeros((num_images,image_rows,image_columns,image_channels))

for i in range(num_images):
    im1=cv2.imread(center_image[i])
    grey[i] = im1
    steering_angle[i] = round(float(steering_angle[i]),2)

####################################################################
# Splitting the input feature set into training and validation set
# to check the loss values on the validation set.
####################################################################
X_train, X_val, y_train, y_val = train_test_split(grey,steering_angle , test_size=0.33, random_state=0)

print("Shape of X_train = ",X_train.shape)
print("Shape of y_train = ",len(y_train))
print("Shape of X_val = ",X_val.shape)
print("Shape of y_val = ",len(y_val))

X_train = X_train.astype('float32')
X_val = X_val.astype('float32')

input_shape = (image_rows, image_columns, image_channels)

######################################################################################################################################################################
# This is a function to create a model with 5 convolutional layers, Flatten, Dropout, RELU, Fully Connected Layer, Dropout, RELU followed by 4 Fully Connected layers.
# Dropout is to avoid overfitting, RELU is to introduce non-linearity in the model. The last Fully Connected layer has only one neuron in this model since this is a regression problem given that the output steering angles are continuous values.
# References:
# Nvidia paper: http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf
# Confluence link: https://chatbotslife.com/learning-human-driving-behavior-using-nvidias-neural-network-model-and-image-augmentation-80399360efee#.6ptu4rq9t
#
######################################################################################################################################################################
def creat_model_nvidia():
    
    model = Sequential()

    model.add(Convolution2D(24, 5, 5, input_shape=input_shape, subsample=(2, 2), border_mode="valid", activation='relu'))
    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode="valid", activation='relu'))
    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode="valid", activation='relu'))
    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode="valid", activation='relu'))
    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode="valid", activation='relu'))
    
    model.add(Flatten())
    #####################################################################################
    # Tried using a dropout rate of 0.3 and 0.5
    #####################################################################################
    model.add(Dropout(0.5))
    model.add(Activation('relu'))

    model.add(Dense(1164))
    model.add(Dropout(0.5))
    model.add(Activation('relu'))
    
    model.add(Dense(100))
    model.add(Dense(50))
    model.add(Dense(10))
    model.add(Dense(1))

    return model

model = creat_model_nvidia()
adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
model.summary()
#################################################################################
# "mse" function to calculate the loss since its a regression problem
#################################################################################
model.compile(optimizer=adam, loss='mse')

###########################################################################
# Leveraged python generator approach in the function so it yields the 
# input features and output values in batches of 20
###########################################################################
batch_size = 20
def batchgen(images,output):
    num_images = len(images)
    print("num_images = ",num_images)
    for i in range(0,num_images,batch_size):
        yield (images[i:i + batch_size],output[i:i + batch_size])
 
###########################################################################
# Test function for batchgen
###########################################################################     
i = 1  
batch = batchgen(X_train,y_train)
for x,y in batch:
    print("Dimension 1 of image 1",len(x))
    print("************")
    print("Dimension 2 of image 1",len(x[0]))
    print("************")
    print("Dimension 3 of image 1",len(x[0][0]))
    print("************")
    print(y)
    i = i + 1
    if(i > 1):
        break
        
###########################################################################
# For anywhere over epoch size of 5, there is no improvement in the loss.
# fit_generator method of keras.model given its a regression problem
# and it fits the model on the data generator batch by batch. Helps with 
# resource constraints
#
# References of fit_generator usage : https://keras.io/models/model/
###########################################################################    
nb_epoch = 5
history = model.fit_generator(batchgen(X_train, y_train), samples_per_epoch = batch_size, nb_epoch = nb_epoch,
                     verbose=1, max_q_size = 10,
                      pickle_safe=False)
                      
###########################################################################
# evaluate the trained model against the validation data set for performance
###########################################################################                     
score = model.evaluate(X_val, y_val, verbose=0)
print('Test score:', score)


#################################################
# generate trained model as a json file
# generate learned weights as h5 file
#################################################
model_json = model.to_json()
with open('model.json', 'w') as f:
    json.dump(model_json, f)
model.save_weights("model.h5")
